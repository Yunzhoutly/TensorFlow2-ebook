TensorFlow2深度學習(深度学习) 電子書(PDF+原始碼) 備份 [TensorFlow2-ebook]

資料來源:https://github.com/dragen1860/Deep-Learning-with-TensorFlow-book

GITHUB: https://github.com/jash-git/TensorFlow2-ebook
 
目 錄
人工智能緒論
1.1 人工智能
1.2 神經網絡發展簡史
1.3 深度學習特點
1.4 深度學習應用
1.5 深度學習框架
1.6 開發環境安裝
1.7 參考文獻
第 2 章 回歸問題
2.1 神經元模型
2.2 優化方法
2.3 線性模型實戰
2.4 線性回歸
2.5 參考文獻
第 3 章分類問題
3.1 手寫數字圖片數據集
3.2 模型搆建
3.3 誤差計算
3.4 真的解決了嗎
3.5 非線性模型
3.6 表達能力
3.7 優化方法
3.8 手寫數字圖片識別體驗
3.9 小結
3.10 參考文獻
第 4 章 TensorFlow 基礎
4.1 數據類型
4.2 數值精度
4.3 待優化張量
4.4 創建張量
4.5 張量的典型應用
4.6 索引與切片
4.7 維度變換
4.8 Broadcasting
4.9 數學運算
4.10 前向傳播實戰
4.11 參考文獻
第 5 章 TensorFlow 進階
5.1 合并與分割
5.2 數據統計
5.3 張量比較
5.4 填充與復制
5.5 數據限幅
5.6 高級操作
5.7 經典數據集加載
5.8 MNIST 測試實戰
5.9 參考文獻
第 6 章 神經網絡
6.1 感知機
6.2 全連接層
6.3 神經網絡
6.4 激活函數
6.5 輸出層設計
6.6 誤差計算
6.7 神經網絡類型
6.8 油耗預測實戰
6.9 參考文獻
第 7 章 反向傳播算法
7.1 導數與梯度
7.2 導數常見性質
7.3 激活函數導數
7.4 損失函數梯度
7.5 全連接層梯度
7.6 鏈式法則
7.7 反向傳播算法
7.8 Himmelblau 函數優化實戰
7.9 反向傳播算法實戰
7.10 參考文獻
第 8 章 Keras 高層接口
8.1 常見功能模塊
8.2 模型裝配、訓練與測試
8.3 模型保存與加載
8.4 自定義類
8.5 模型樂園
8.6 測量工具
8.7 可視化
8.8 參考文獻
第 9 章 過擬合
9.1 模型的容量
9.2 過擬合與欠擬合
9.3 數據集划分
9.4 模型設計
9.5 正則化
9.6 Dropout
9.7 數據增強
9.8 過擬合問題實戰
9.9 參考文獻
第 10 章 卷積神經網絡
10.1 全連接網絡的問題
10.2 卷積神經網絡
10.3 卷積層實現
10.4 LeNet-5 實戰
10.5 表示學習
10.6 梯度傳播
10.7 池化層
10.8 BatchNorm 層
10.9 經典卷積網絡
10.10 CIFAR10 與VGG13 實戰
10.11 卷積層變種
10.12 深度殘差網絡
10.13 DenseNet
10.14 CIFAR10 與ResNet18 實戰
10.15 參考文獻
第 11 章 循環神經網絡
11.1 序列表示方法
11.2 循環神經網絡
11.3 梯度傳播
11.4 RNN 層使用方法
11.5 RNN 情感分類問題實戰
11.6 梯度彌散和梯度爆炸
11.7 RNN 短時記憶
11.8 LSTM 原理
11.9 LSTM 層使用方法
11.10 GRU 簡介
11.11 LSTM/GRU 情感分類問題再戰
11.12 預訓練的詞向量
11.13 參考文獻
第 12 章 自編碼器
12.1 自編碼器原理
12.2 MNIST 圖片重建實戰
12.3 自編碼器變種
12.4 變分自編碼器
12.5 VAE 實戰
12.6 參考文獻
第 13 章 生成對抗網絡
13.1 博弈學習實例
13.2 GAN 原理
13.3 DCGAN 實戰
13.4 GAN 變種
13.5 納什均衡
13.6 GAN 訓練難題
13.7 WGAN 原理
13.8 WGAN-GP 實戰
13.9 參考文獻
第 14 章 強化學習
14.1 先睹為快
14.2 強化學習問題
14.3 策略梯度方法
14.4 值函數方法
14.5 Actor-Critic 方法
14.6 小結
14.7 參考文獻
第15 章 自定義數據集
15.1 精靈寶可夢數據集
15.2 自定義數據集加載流程
15.3 寶可夢數據集實戰
15.4 遷移學習
15.5 Saved_model
15.6 模型部署
15.7 參考文獻